# -*- coding: utf-8 -*-
#"""hybrid search faq_llm.ipynb
#Automatically generated by Colab.
#Original file is located at
#    https://colab.research.google.com/drive/1NU4G-yKATt31FA_to3NL9hHWcWOI7y5M
#"""

#!pip install -q langchain langchain_cohere langchain_google_genai chromadb langchainhub langchain_community huggingface_hub langchain_openai lancedb openai tiktoken rank_bm25 pypdf

import os
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import pandas as pd
import lancedb
from langchain_community.vectorstores import LanceDB
from langchain_community.document_loaders import DataFrameLoader
from langchain_community.retrievers import BM25Retriever
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from langchain_openai import OpenAIEmbeddings
from langchain.retrievers import EnsembleRetriever
from langchain import PromptTemplate
from imap_tools import MailBox
    
os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
os.environ["COHERE_API_KEY"] = COHERE_API_KEY
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# """Load Data"""

df = pd.read_csv("./content/context.csv")
loader = DataFrameLoader(df, page_content_column="data")
docs = loader.load()

embedding = OpenAIEmbeddings()

# """Split sentences"""

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=200, add_start_index=True
)
all_splits = text_splitter.split_documents(docs)

bm25_retriever = BM25Retriever.from_documents(all_splits)
bm25_retriever.k = 3  # Retrieve top 3 results

ALL_TEXT = " ".join([doc.page_content for doc in all_splits])
db = lancedb.connect("/tmp/lancedb")
table = db.create_table(
    "pandas_docs",
    data=[
        {
            "vector": embedding.embed_query("MSCS"),
            "text": "MSCS",
            "id": "1",
        },
        {
            "vector": embedding.embed_query("GRE"),
            "text": "GRE",
            "id": "2",
        }
    ],
    mode="overwrite",
)
docsearch = LanceDB.from_texts(ALL_TEXT, embedding, connection=db)
retriever_lancedb = docsearch.as_retriever(search_kwargs={"k": 3})

# """Generate embeddings for the data"""

retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, retriever_lancedb], weights=[0.2, 0.8]
)

# """## Gemini"""

llm = ChatGoogleGenerativeAI(model="gemini-pro")

TEMPLATE = """
  You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.
  The answer could come from the retrieved context or could be answered by following a hyperlink. Use the description of the hyperlink
  to infer if the hyperlink could provide a possible answer.
  If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. 

  CONTEXT:
  {context}

  QUESTION:
  {query}

  ANSWER:
  """

prompt = PromptTemplate(input_variables=["query", "context"], template=TEMPLATE)

def format_docs(documents):
    """Formats documents."""
    return "\n\n".join(doc.page_content for doc in documents)

rag_chain_from_docs = (
    RunnablePassthrough.assign(context=(lambda x: format_docs(x["context"])))
    | prompt
    | llm
    | StrOutputParser()
)

rag_chain_with_source = RunnableParallel(
    {"context": retriever, "query": RunnablePassthrough()}
).assign(answer=rag_chain_from_docs)

# Connect to the SMTP server
SMTP_SERVER = 'smtp.gmail.com'
PORT = 587
server = smtplib.SMTP(SMTP_SERVER, PORT)
server.starttls()
# Login to the server
server.login(EMAIL, PASS)
# Iterate through each email message and print its contents
# Credit to stackoverflow user https://stackoverflow.com/questions/5632713/getting-n-most-recent-emails-using-imap-and-python
with MailBox('imap.gmail.com').login(EMAIL, PASS, 'INBOX') as mailbox:
    for msg in mailbox.fetch(limit=1, reverse=True):
        SENDER_EMAIL = 'realalandisayupov@gmail.com'
        RECEIVER_EMAIL = 'steamuservni@gmail.com'
        message = MIMEMultipart()
        message['From'] = SENDER_EMAIL
        message['To'] = RECEIVER_EMAIL
        message['Subject'] = 'Answer Email'
        BODY = str(rag_chain_with_source.invoke(msg.text)['answer'])
        print(BODY)
        message.attach(MIMEText(BODY, 'plain'))
        # Send the email
        server.sendmail(SENDER_EMAIL, RECEIVER_EMAIL, message.as_string())

# """## Testing"""

# with open("./content/questions.txt", "r") as pFile:
#     pLines = [
#         # strip() - Removes leading/trailing whitespace.
#         line.strip()
#             # readlines() - Reads all the lines of a file an returns them as a list.
#             for line in pFile.readlines()]
# for line in pLines:
#   print(line)
#   print(rag_chain_with_source.invoke(line))
#   print("________")
