{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE3Hend1Sa6s"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain_cohere langchain_google_genai chromadb langchainhub langchain_community huggingface_hub langchain_openai lancedb openai tiktoken rank_bm25 pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import DataFrameLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_cohere import CohereEmbeddings\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "from langchain.vectorstores import LanceDB\n",
        "import lancedb\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "o8U52mVbSoh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = \"-\"\n",
        "os.environ[\"COHERE_API_KEY\"] = \"-\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"-\""
      ],
      "metadata": {
        "id": "yXufsZb3Srhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/context2.csv\")\n",
        "loader = DataFrameLoader(df, page_content_column=\"data\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "s01YrHfvSti3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "nbfod2jmSu1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "eWSSoDlmSv2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm25_retriever = BM25Retriever.from_documents(all_splits)\n",
        "bm25_retriever.k = 3  # Retrieve top 3 results"
      ],
      "metadata": {
        "id": "jEDOZJtUSxCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text = \" \".join([doc.page_content for doc in all_splits])\n",
        "db = lancedb.connect(\"/tmp/lancedb\")\n",
        "table = db.create_table(\n",
        "    \"pandas_docs\",\n",
        "    data=[\n",
        "        {\n",
        "            \"vector\": embedding.embed_query(\"RUWireless Secure\"),\n",
        "            \"text\": \"RUWireless Secure\",\n",
        "            \"id\": \"1\",\n",
        "        },\n",
        "        {\n",
        "            \"vector\": embedding.embed_query(\"ScarletMail\"),\n",
        "            \"text\": \"ScarletMail\",\n",
        "            \"id\": \"2\",\n",
        "        }\n",
        "    ],\n",
        "    mode=\"overwrite\",\n",
        ")\n",
        "docsearch = LanceDB.from_texts(all_text, embedding, connection=db)\n",
        "retriever_lancedb = docsearch.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "cko_83u6Sydh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=CohereEmbeddings(model=\"embed-english-light-v3.0\"))"
      ],
      "metadata": {
        "id": "G0jy70UuSzru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = EnsembleRetriever(\n",
        "    retrievers=[bm25_retriever, retriever_lancedb], weights=[0.2, 0.8]\n",
        ")"
      ],
      "metadata": {
        "id": "PUG2FGdfS0xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
      ],
      "metadata": {
        "id": "UXJw651xS2Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "template = \"\"\"\n",
        "  You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
        "  The answer could come from the retrieved context or could be answered by following a hyperlink. Use the description of the hyperlink\n",
        "  to infer if the hyperlink could provide a possible answer.\n",
        "  If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
        "\n",
        "  CONTEXT:\n",
        "  {context}\n",
        "\n",
        "  QUESTION:\n",
        "  {query}\n",
        "\n",
        "  ANSWER:\n",
        "  \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"query\", \"context\"], template=template)"
      ],
      "metadata": {
        "id": "9dbQhMaxS3lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "3CCVWcdbS4tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain_from_docs = (\n",
        "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain_with_source = RunnableParallel(\n",
        "    {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
        ").assign(answer=rag_chain_from_docs)"
      ],
      "metadata": {
        "id": "OH-SDSXES6Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/questions.txt\", \"r\") as pFile:\n",
        "    pLines = [\n",
        "        # strip() - Removes leading/trailing whitespace.\n",
        "        line.strip()\n",
        "            # readlines() - Reads all the lines of a file an returns them as a list.\n",
        "            for line in pFile.readlines()]\n",
        "for line in pLines:\n",
        "  print(line)\n",
        "  print(rag_chain_with_source.invoke(line))"
      ],
      "metadata": {
        "id": "D21Ty4zoS8pb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
